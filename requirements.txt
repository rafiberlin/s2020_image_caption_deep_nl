# Automatically generated by https://github.com/damnever/pigar.

# sose2020_image_caption_deep_learning/src/preprocessing.py: 15
funcy == 1.14

# sose2020_image_caption_deep_learning/src/main.py: 12
# sose2020_image_caption_deep_learning/utils/glove_conv.py: 2,3
gensim == 3.8.3

# sose2020_image_caption_deep_learning/src/preprocessing.py: 11
nltk == 3.5

# sose2020_image_caption_deep_learning/src/main.py: 9
# sose2020_image_caption_deep_learning/src/model.py: 5
numpy == 1.18.3

# sose2020_image_caption_deep_learning/src/main.py: 19
# sose2020_image_caption_deep_learning/src/model.py: 13
pandas == 1.0.3

# sose2020_image_caption_deep_learning/src/main.py: 14,16,17,18
# sose2020_image_caption_deep_learning/src/model.py: 9,10,11,14,15,16
pycocoevalcap == 1.1

# sose2020_image_caption_deep_learning/src/main.py: 15
pycocotools == 2.0.1

# sose2020_image_caption_deep_learning/src/preprocessing.py: 16
scikit_learn == 0.22.2.post1

# sose2020_image_caption_deep_learning/src/main.py: 1,3,6,7,8
# sose2020_image_caption_deep_learning/src/model.py: 1,2,3,4,12
# sose2020_image_caption_deep_learning/src/preprocessing.py: 7
torch == 1.5.0

# sose2020_image_caption_deep_learning/src/main.py: 2,5
# sose2020_image_caption_deep_learning/src/preprocessing.py: 3,5,6
torchvision == 0.6.0

# sose2020_image_caption_deep_learning/src/preprocessing.py: 12
tqdm == 4.45.0
